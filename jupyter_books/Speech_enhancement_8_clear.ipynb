{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f9b45c3",
   "metadata": {
    "id": "8f9b45c3"
   },
   "source": [
    "# a project to enhance the apparent quality of microphone in real time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ab275d",
   "metadata": {
    "id": "57ab275d"
   },
   "source": [
    "## loading the useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WMCT8TTKmR7C",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1707243417244,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "WMCT8TTKmR7C",
    "outputId": "484a5f7f-128d-49c4-b778-1a437e880690",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this notebook is able to run both locally and in google colab\n",
    "#if running in google colab, some additional actions need to be performed\n",
    "#The variable IN_COLAB tells the code whether to perform those actions\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "IN_COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310f3c67",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1707243418044,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "310f3c67"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b0e4f8",
   "metadata": {
    "executionInfo": {
     "elapsed": 2976,
     "status": "ok",
     "timestamp": 1707243424597,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "01b0e4f8"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torchaudio\n",
    "from IPython.display import Audio #play back the signal (original waveform)\n",
    "import  IPython\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eVJmx_1jWBQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4577,
     "status": "ok",
     "timestamp": 1707243429172,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "5eVJmx_1jWBQ",
    "outputId": "37dc3552-5161-4d8a-9675-fab8270ec5bb"
   },
   "outputs": [],
   "source": [
    "#install audio_preprocessing from github - this is necessary if running in Google Colab, otherwise not necessary\n",
    "if (IN_COLAB):\n",
    "   #!git clone https://github.com/RomanZhvanskiy/microphone_enhancer_gh.git\n",
    "   !git -C \"microphone_enhancer_gh\" pull || git clone https://github.com/RomanZhvanskiy/microphone_enhancer_gh.git \"microphone_enhancer_gh\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ll-_x8c465u0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1707243429172,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "Ll-_x8c465u0",
    "outputId": "fdc83167-0483-4210-fc9e-38c7667fd90f"
   },
   "outputs": [],
   "source": [
    "if (IN_COLAB):  # it is also necessary to change directory in Google Colab to load audio_preprocessing\n",
    "  %cd /content/microphone_enhancer_gh/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_hrKTv2n3dfl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1793,
     "status": "ok",
     "timestamp": 1707243430961,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "_hrKTv2n3dfl",
    "outputId": "483c0e4c-e685-4e40-a6bd-055327c4ad8f"
   },
   "outputs": [],
   "source": [
    "if (IN_COLAB): # switch to the appropriate branch\n",
    "  !git checkout better_models_and_gridsearch\n",
    "  !git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e518d6-2838-478c-81da-1d36b4e4ed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "print(sys.argv[0])\n",
    "print(os.path.dirname(os.path.realpath('__file__')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b1ac09-c32f-4c09-82b5-9add3c469103",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import os.path\n",
    "sys.path.append(\n",
    "    os.path.dirname(os.path.realpath('__file__')))\n",
    "\n",
    "sys.path.append(\n",
    "    \"/\".join(os.path.realpath('__file__').split (\"/\")[0:-2])) #root\n",
    "\n",
    "sys.path.append( \"/\".join(os.path.realpath('__file__').split (\"/\")[0:-2]) + \"/Back_end\") #root\n",
    "sys.path.append( \"/\".join(os.path.realpath('__file__').split (\"/\")[0:-2]) + \"/Back_end/api\"                  ) \n",
    "sys.path.append( \"/\".join(os.path.realpath('__file__').split (\"/\")[0:-2]) + \"/Back_end/audio_cache\"          ) \n",
    "sys.path.append( \"/\".join(os.path.realpath('__file__').split (\"/\")[0:-2]) + \"/Back_end/audio_preprocessing\"  ) \n",
    "sys.path.append( \"/\".join(os.path.realpath('__file__').split (\"/\")[0:-2]) + \"/Back_end/hugging_models\"       ) \n",
    "sys.path.append( \"/\".join(os.path.realpath('__file__').split (\"/\")[0:-2]) + \"/Back_end/image_metrics\"        ) \n",
    "sys.path.append( \"/\".join(os.path.realpath('__file__').split (\"/\")[0:-2]) + \"/Back_end/interface\"            ) \n",
    "sys.path.append( \"/\".join(os.path.realpath('__file__').split (\"/\")[0:-2]) + \"/Back_end/ml_logic\"             ) \n",
    "sys.path.append( \"/\".join(os.path.realpath('__file__').split (\"/\")[0:-2]) + \"/Back_end/pretrained_models\"    ) \n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77991dea",
   "metadata": {
    "executionInfo": {
     "elapsed": 740,
     "status": "ok",
     "timestamp": 1707243431697,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "77991dea"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from audio_preprocessing import preprocessing as pp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204fa7a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1707243431697,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "204fa7a4",
    "outputId": "b2834045-d9a0-4f12-eadf-2f3e2dcb59bb"
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q9JvwZATpIG-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52784,
     "status": "ok",
     "timestamp": 1707243484477,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "q9JvwZATpIG-",
    "outputId": "8246e2a5-7473-4367-fbf0-949751b9eb41"
   },
   "outputs": [],
   "source": [
    "if (IN_COLAB):  # the training data is loaded in the google drive for the purpose of being used in google colab\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/gdrive')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dGtDRUs-pk9M",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 556,
     "status": "ok",
     "timestamp": 1707243485030,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "dGtDRUs-pk9M",
    "outputId": "36011b1a-2698-441a-95f3-5930babe64f7"
   },
   "outputs": [],
   "source": [
    "#!ls -la /content/gdrive/MyDrive/'Colab Notebooks'/data_audio/VCTK-Corpus/wav48\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7OzkGMmS5Y1V",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 406,
     "status": "ok",
     "timestamp": 1707243492548,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "7OzkGMmS5Y1V",
    "outputId": "c7be86e5-db32-4b6b-fc2d-5807ddfba3e8"
   },
   "outputs": [],
   "source": [
    "#os.listdir(\"/content/gdrive/MyDrive/Colab Notebooks/data_audio/VCTK-Corpus/wav48\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcb6371",
   "metadata": {
    "id": "2fcb6371"
   },
   "source": [
    "### Degrade quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa927307",
   "metadata": {
    "executionInfo": {
     "elapsed": 1091,
     "status": "ok",
     "timestamp": 1707243580277,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "fa927307"
   },
   "outputs": [],
   "source": [
    "def degrade_quaity(spectrogram, sr, upper_limit=3000.0, lower_limit=100.0, insensitive_level = 0.5,relative_noise_level=0.1, debug=0):\n",
    "    degraded_spectrogram = pp.mel_spectrogram_remove_frequency(\n",
    "            spectrogram,\n",
    "            sr,\n",
    "            remove_above=upper_limit,\n",
    "            remove_below=lower_limit,\n",
    "            debug=debug)\n",
    "\n",
    "\n",
    "    #remove quiet sounds  (our simulated bad microphone cannot capture quiet sounds)\n",
    "    degraded_spectrogram = pp.mel_spectrogram_remove_quiet_sounds (\n",
    "            degraded_spectrogram,\n",
    "            sr,\n",
    "            remove_below=insensitive_level,\n",
    "            debug=debug)\n",
    "\n",
    "    #add noise (our simulated bad microphone also captures noize)\n",
    "    degraded_spectrogram = pp.mel_spectrogram_add_noise(degraded_spectrogram,\n",
    "            sr,\n",
    "            relative_noise_level=relative_noise_level,\n",
    "            add_above=lower_limit,\n",
    "            add_below=upper_limit,\n",
    "            debug=debug)\n",
    "    return degraded_spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4924ba38",
   "metadata": {
    "id": "4924ba38"
   },
   "source": [
    "### Convert MEL spectrogram to waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e2cf30",
   "metadata": {
    "id": "a1e2cf30"
   },
   "outputs": [],
   "source": [
    "pp.plot_mel_spectrogram(spectrogram,sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba81e74",
   "metadata": {
    "id": "cba81e74",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pp.plot_mel_spectrogram(degraded_x,sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ccd464",
   "metadata": {
    "id": "45ccd464"
   },
   "outputs": [],
   "source": [
    "#https://datasciencedojo.com/blog/python-libraries-for-generative-ai/#\n",
    "#https://huggingface.co/docs/diffusers/tutorials/basic_training\n",
    "#library for distortions\n",
    "#https://github.com/iver56/audiomentations?tab=readme-ov-file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3115e16",
   "metadata": {
    "id": "d3115e16"
   },
   "source": [
    "## training a simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e69b31",
   "metadata": {
    "id": "c3e69b31"
   },
   "source": [
    "### data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a8e18f-1979-4794-a430-c88416aec266",
   "metadata": {},
   "outputs": [],
   "source": [
    "where_to_get_training_data = \"/\".join(os.path.realpath('__file__').split (\"/\")[0:-2]) + \"/Data/raw_data/VCTK-Corpus/wav48\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb09f07-9044-4be3-8e0f-7da1a3106eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"where_to_get_training_data = {where_to_get_training_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd9f162",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23735,
     "status": "ok",
     "timestamp": 1707243529615,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "fbd9f162",
    "outputId": "36f77917-0599-48da-aaa6-f84cc610a5f9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "large_data, sr = pp.get_all_speech_as_one_mel(where_to_get_training_data= where_to_get_training_data , num_spectrograms=100, num_speaker =0, debug = 1,working_in_google_colab = IN_COLAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba34c1a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1054,
     "status": "ok",
     "timestamp": 1707243536943,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "ba34c1a2",
    "outputId": "b43563de-3fab-4cae-a5f6-304cf3294c5e"
   },
   "outputs": [],
   "source": [
    "train_sg, test_sg = pp.split_spectrogram_in_train_and_test(large_data,0.2, debug=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299758aa",
   "metadata": {
    "executionInfo": {
     "elapsed": 542,
     "status": "ok",
     "timestamp": 1707243585590,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "299758aa"
   },
   "outputs": [],
   "source": [
    "#degrade quality of both train and test\n",
    "degraded_train_sg =pp.degrade_quaity(train_sg, sr )\n",
    "degraded_test_sg =pp.degrade_quaity(test_sg, sr )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jDejF5zKpWvB",
   "metadata": {
    "executionInfo": {
     "elapsed": 62779,
     "status": "ok",
     "timestamp": 1707243690538,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "jDejF5zKpWvB"
   },
   "outputs": [],
   "source": [
    "\n",
    "reconstructed_test = pp.spectrogram_2_waveform (test_sg, sr=sr)\n",
    "reconstructed_degraded_test = pp.spectrogram_2_waveform (degraded_test_sg, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h-qGcgiwpj6t",
   "metadata": {
    "id": "h-qGcgiwpj6t"
   },
   "outputs": [],
   "source": [
    "reconstructed_train = pp.spectrogram_2_waveform (train_sg, sr=sr)\n",
    "reconstructed_degraded_train = pp.spectrogram_2_waveform (degraded_train_sg, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca2e84a-1816-41fc-8113-939721f62d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (IN_COLAB):\n",
    "    where_to_get_preprocessed_training_data = \"/content/gdrive/MyDrive/Colab Notebooks/data_audio\"\n",
    "else:\n",
    "    where_to_get_preprocessed_training_data = \"/\".join(os.path.realpath('__file__').split (\"/\")[0:-2]) + \"/Data/postprocessed_training_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Jb3OmiJzBYCI",
   "metadata": {
    "executionInfo": {
     "elapsed": 4192,
     "status": "ok",
     "timestamp": 1707233482342,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "Jb3OmiJzBYCI"
   },
   "outputs": [],
   "source": [
    "#the above can take a long time on large datasets, so I'll save the results to file\n",
    "np.savetxt(fname=where_to_get_preprocessed_training_data + \"/train_sg.sg\", X=train_sg)\n",
    "np.savetxt(fname=where_to_get_preprocessed_training_data + \"/test_sg.sg\", X=test_sg)\n",
    "np.savetxt(fname=where_to_get_preprocessed_training_data + \"/degraded_train_sg.sg\", X=degraded_train_sg)\n",
    "np.savetxt(fname=where_to_get_preprocessed_training_data + \"/degraded_test_sg.sg\", X=degraded_test_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764c735b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "executionInfo": {
     "elapsed": 44948,
     "status": "ok",
     "timestamp": 1707244168908,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "764c735b",
    "outputId": "346989a6-66bc-4f29-d462-558787d7bc50"
   },
   "outputs": [],
   "source": [
    "\n",
    "print (\"audio reconstructed_test\")\n",
    "IPython.display.display(IPython.display.Audio(reconstructed_test,  rate=sr))\n",
    "pp.plot_mel_spectrogram(test_sg,sr, figsize=(2,2))\n",
    "\n",
    "print (\"audio degraded_test_sg\")\n",
    "IPython.display.display(IPython.display.Audio(reconstructed_degraded_test,  rate=sr))\n",
    "pp.plot_mel_spectrogram(degraded_train_sg,sr, figsize=(2,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ab5062-af08-45ca-9330-c8225dfd8719",
   "metadata": {},
   "source": [
    "## https://keras.io/examples/vision/autoencoder/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4a1dce-03b0-4000-8fd1-76e34c4b2e8d",
   "metadata": {},
   "source": [
    "this model actually works on 2D images -we need to split the input into a number of 256x256 images. In addition, we will take logs of input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96f0bab-05fe-45a5-b016-a2db4e767a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_long = np.log( degraded_train_sg + 0.0000001)\n",
    "re_long = np.log( train_sg + 0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c51cfe-c558-4925-9354-410f1135cccd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (f\"inp_long.shape = {inp_long.shape}, re_long.shape = {re_long.shape}\")\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(inp_long )\n",
    "plt.figure()\n",
    "plt.imshow(re_long )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048f1394-4d6d-4726-84fe-81ca8355a435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import expand_dims\n",
    "\n",
    "def spectrogram_2_series_of_images(sg, debug=0):\n",
    "    #calculate number of 256x256 images to split SG in\n",
    "    numImages = int(sg.shape[1]/256)\n",
    "    #reduce the length of SG so that it is evenly divisible by 256 - then it can be nicely reshaped\n",
    "    sg_for_reshape = sg[:,0:numImages*256 ]\n",
    "    if (debug):\n",
    "        print(f\"inp_long_for_reshape.shape={sg_for_reshape.shape}\")\n",
    "        \n",
    "    sg_reshaped = sg_for_reshape.reshape(256, 256, numImages)\n",
    "    #sg_reshaped has dimensions (n_x, n_y, n_image). We need shape (n_image, n_x, n_y) for tensorflow input\n",
    "    #use swapaxes method to achieve the correct shape\n",
    "    sg_reshaped_out = sg_reshaped.swapaxes(0, 2).swapaxes(1,2)\n",
    "\n",
    "    #Convolutional Neural Network models need to be fed with images whose last dimension is the number of channels\n",
    "    #The shape of tensors fed into ***ConvNets*** is the following: `(NUMBER_OF_IMAGES, HEIGHT, WIDTH, CHANNELS)`\n",
    "    #add 1 channel as the last dimension\n",
    "    sg_reshaped_out = expand_dims(sg_reshaped_out, axis=-1)\n",
    "    \n",
    "\n",
    "    if (debug):\n",
    "        print(f\"sg_reshaped_out.shape={sg_reshaped_out.shape}\")\n",
    "\n",
    "    \n",
    "    return sg_reshaped_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9ff893-9a1a-4154-9a76-069519c479be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "inp_long = np.log( degraded_train_sg + 0.0000001)\n",
    "re_long = np.log( train_sg + 0.0000001)\n",
    "test_inp_long = np.log( degraded_test_sg + 0.0000001)\n",
    "test_re_long = np.log( test_sg + 0.0000001)\n",
    "\n",
    "data_inp_series_of_images = tf.convert_to_tensor(spectrogram_2_series_of_images(inp_long, debug=1))\n",
    "data_re_series_of_images = tf.convert_to_tensor(spectrogram_2_series_of_images(re_long))\n",
    "data_test_inp_series_of_images = tf.convert_to_tensor(spectrogram_2_series_of_images(test_inp_long, debug=1))\n",
    "data_test_re_series_of_images = tf.convert_to_tensor(spectrogram_2_series_of_images(test_re_long))\n",
    "\n",
    "\n",
    "print(f\"data_inp_series_of_images.shape={data_inp_series_of_images.shape}, data_re_series_of_images.shape={data_re_series_of_images.shape}, \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04f8171-7767-44fb-ae65-c11e0ad466db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(data_inp_series_of_images[56, :,:, 0] )\n",
    "plt.figure()\n",
    "plt.imshow(data_re_series_of_images[56, :,:, 0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f546f18-fea3-4427-b44d-d5354b1904cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "input = layers.Input(shape=(256, 256, 1))\n",
    "\n",
    "# Encoder\n",
    "x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input)\n",
    "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "x = layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPooling2D((2, 2), padding=\"same\")(x)\n",
    "\n",
    "# Decoder\n",
    "x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.Conv2D(1, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "# Autoencoder\n",
    "optimizer = Adam(lr=0.01)\n",
    "autoencoder = Model(input, x)\n",
    "autoencoder.compile(optimizer=optimizer, loss=\"mae\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64f56eb-c8b8-41c7-9321-4c753cd25df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=autoencoder.fit(\n",
    "    x=data_inp_series_of_images,\n",
    "    y=data_re_series_of_images,\n",
    "    epochs=25,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    validation_data=(data_test_inp_series_of_images, data_test_re_series_of_images),\n",
    ")\n",
    "\n",
    "#data_test_inp_series_of_images = tf.convert_to_tensor(spectrogram_2_series_of_images(test_inp_long, debug=1))\n",
    "#data_test_re_series_of_images = tf.convert_to_tensor(spectrogram_2_series_of_images(test_re_long))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab50e62-2f75-4de1-86f2-2c8a63bbb529",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history)\n",
    "headers = list(hist_df.columns.values)\n",
    "#plot = hist_df[[headers[0], headers[2]]].plot(title=f\"{headers[0]}, {headers[2]}\", logy=True)\n",
    "plot = hist_df[headers[0]].plot(title=f\"{headers[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb9b12d-264a-4f91-8447-835f338160b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = autoencoder.predict(data_test_inp_series_of_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8b659d-d443-4217-87f6-1d3d3806c3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"predictions.shape={predictions.shape} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7808f24-fcc6-4235-a22e-bec9ed923efc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(predictions[0, :,:, 0] )\n",
    "plt.figure()\n",
    "plt.imshow(data_re_series_of_images[0, :,:, 0] )\n",
    "plt.figure()\n",
    "plt.imshow(data_test_inp_series_of_images[0, :,:, 0] )\n",
    "\n",
    "#    validation_data=(data_test_inp_series_of_images, data_test_re_series_of_images),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c338398-8359-4b0e-a602-445582780d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_X_series_of_images, data_train_Y_series_of_images, data_test_X_series_of_images,data_test_Y_series_of_images = pp.get_all_speech_as_series_of_images(num_spectrograms=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65349402-40ef-453b-b32d-444fde01e441",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"data_train_X_series_of_images.shape={data_train_X_series_of_images.shape}\")\n",
    "print(f\"data_train_Y_series_of_images.shape={data_train_Y_series_of_images.shape}\")\n",
    "print(f\" data_test_X_series_of_images.shape={ data_test_X_series_of_images.shape}\")\n",
    "print(f\" data_test_Y_series_of_images.shape={ data_test_Y_series_of_images.shape}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6125e3c-3a97-487c-95c6-75f83d8404fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, data_test_X_series_of_images.shape[0]):\n",
    "    print (f\"i = {i}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adaeb01-3911-426c-bbf9-710b9064255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ede3881-741e-4b46-8f94-6eb488bbdd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_sg = pp.series_of_images_2_spectrogram(predictions, debug=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a422e0-8dd4-4e8b-8e4d-8111cf09f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"audio predictions_sg\")\n",
    "IPython.display.display(IPython.display.Audio(pp.spectrogram_2_waveform (predictions_sg,sr),  rate=sr))  \n",
    "pp.plot_mel_spectrogram(predictions_sg,sr, figsize=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c46523-d29e-4f52-979c-1252ec74b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y_sg = pp.series_of_images_2_spectrogram(data_test_Y_series_of_images, debug=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de2772e-026b-4020-b4e5-953a4ef3a0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"audio predictions_sg\")\n",
    "IPython.display.display(IPython.display.Audio(pp.spectrogram_2_waveform (test_Y_sg,sr),  rate=sr))  \n",
    "pp.plot_mel_spectrogram(test_Y_sg,sr, figsize=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2946392-c818-4ff6-8788-bca92b664c0a",
   "metadata": {},
   "source": [
    "## https://keras.io/examples/vision/mirnet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dca5d5-879c-4fc1-87a2-163274401d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d36cdfe-6374-48f3-b4a2-396645539280",
   "metadata": {},
   "source": [
    "## https://huggingface.co/keras-io/lowlight-enhance-mirnet/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66f6bb4-59f0-418d-bbba-91fe7697e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "\n",
    "fpath = \"/home/romanz/code/RomanZhvanskiy/microphone_enhancer_gh/Data/pretrained_models/lowlight-enhance-mirnet/saved_model.pb\"\n",
    "model_mirnet = models.load_model(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6566ad-0c22-47dd-aba0-b5632b3f5568",
   "metadata": {
    "id": "d73a0adb"
   },
   "source": [
    "### model - pix2pix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623c71f4-e916-4147-9b3f-5924e82d3202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "  if apply_batchnorm:\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "  result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f686514b-0d34-4f5d-80a1-acefff4d83a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(filters, size, apply_dropout=False):\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(\n",
    "    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                    use_bias=False))\n",
    "\n",
    "  result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "  if apply_dropout:\n",
    "      result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "  result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fb12e0-054c-4cc9-894f-0d5c0e30f351",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_long = degraded_train_sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d898d11-e0bf-446a-8f22-0ffd5d134b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_long = train_sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a565a4-6d5b-49f5-b263-c8c136290868",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"inp_long.shape = {inp_long.shape}, re_long.shape = {re_long.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28407eae-90ad-48f9-bcb2-a1f1332465bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(inp_long / 255.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dd0e59-de94-4024-9e32-a1c65de38b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = np.log(inp_long[:, 0:256] + 0.0000001) # inp_long[:, 0:255] added  + 0.0000001 to  prevent log 0\n",
    "re = np.log(re_long[:, 0:256] + 0.0000001)\n",
    "print (f\"inp.shape = {inp.shape}, re.shape = {re.shape}\")\n",
    "plt.figure()\n",
    "plt.imshow(inp / 255.0)\n",
    "plt.figure()\n",
    "plt.imshow(re / 255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bd39be-9056-468e-a945-ca13f8815ce5",
   "metadata": {},
   "source": [
    "## https://keras.io/examples/vision/zero_dce/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24de4de4-6797-487a-bfbd-59e60a09d0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dce_net():\n",
    "    input_img = keras.Input(shape=[None, None, 3])\n",
    "    conv1 = layers.Conv2D(\n",
    "        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n",
    "    )(input_img)\n",
    "    conv2 = layers.Conv2D(\n",
    "        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n",
    "    )(conv1)\n",
    "    conv3 = layers.Conv2D(\n",
    "        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n",
    "    )(conv2)\n",
    "    conv4 = layers.Conv2D(\n",
    "        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n",
    "    )(conv3)\n",
    "    int_con1 = layers.Concatenate(axis=-1)([conv4, conv3])\n",
    "    conv5 = layers.Conv2D(\n",
    "        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n",
    "    )(int_con1)\n",
    "    int_con2 = layers.Concatenate(axis=-1)([conv5, conv2])\n",
    "    conv6 = layers.Conv2D(\n",
    "        32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\"\n",
    "    )(int_con2)\n",
    "    int_con3 = layers.Concatenate(axis=-1)([conv6, conv1])\n",
    "    x_r = layers.Conv2D(24, (3, 3), strides=(1, 1), activation=\"tanh\", padding=\"same\")(\n",
    "        int_con3\n",
    "    )\n",
    "    return keras.Model(inputs=input_img, outputs=x_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6052e9c-8ca7-4698-9f27-91298ca6e5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_constancy_loss(x):\n",
    "    mean_rgb = tf.reduce_mean(x, axis=(1, 2), keepdims=True)\n",
    "    mr, mg, mb = (\n",
    "        mean_rgb[:, :, :, 0],\n",
    "        mean_rgb[:, :, :, 1],\n",
    "        mean_rgb[:, :, :, 2],\n",
    "    )\n",
    "    d_rg = tf.square(mr - mg)\n",
    "    d_rb = tf.square(mr - mb)\n",
    "    d_gb = tf.square(mb - mg)\n",
    "    return tf.sqrt(tf.square(d_rg) + tf.square(d_rb) + tf.square(d_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4af936-cb84-4ad9-b44b-27ee41c79737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exposure_loss(x, mean_val=0.6):\n",
    "    x = tf.reduce_mean(x, axis=3, keepdims=True)\n",
    "    mean = tf.nn.avg_pool2d(x, ksize=16, strides=16, padding=\"VALID\")\n",
    "    return tf.reduce_mean(tf.square(mean - mean_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b858b2-3fb7-4b3b-acd6-939218447998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a403fdff-dc70-4e23-9336-d339355a5eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "  if apply_batchnorm:\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "  result.add(tf.keras.layers.LeakyReLU())\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7429a5-6fa8-47fa-9858-09dbe46e4fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#as the documentation says: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
    "#you need a 4 dimensional input for Conv2d layer. you have to a add a channel either after or before 2 main dimensions of the image:\n",
    "\n",
    "#train_images = train_images.reshape(train_size, height, width, 1)\n",
    "\n",
    "#or\n",
    "\n",
    "#train_images = train_images.reshape(train_size, 1, height, width)\n",
    "\n",
    "#in both cases you have to define the art of input in every layer in the network with data_format=\"channels_first\" or data_format=\"channels_last\".\n",
    "#for example:\n",
    "#ncoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2, data_format=\"channels_last\")(encoder_input)\n",
    "\n",
    "\n",
    "down_model = downsample(3, 4)\n",
    "\n",
    "#image is a 256 x 256 array\n",
    "#add a dimension on the end to account for channels\n",
    "inp = tf.expand_dims(inp, -1) # expand dimensions as \"channels last\"\n",
    "#add a dimension on the front to account for batch_size\n",
    "inp = tf.expand_dims(inp, 0)\n",
    "print (f\"inp.shape = {inp.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884a0820-d40d-4110-bde5-091697923b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "down_model = downsample(3, 4)\n",
    "down_result = down_model(tf.expand_dims(inp, 0))\n",
    "print (down_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5e4f41-630b-4b28-b963-4136e94f1a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "up_model = upsample(3, 4)\n",
    "up_result = up_model(tf.squeeze(down_result,axis=0))\n",
    "print (up_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bcaea7-3fc9-449a-beb5-5f6813b92bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator():\n",
    "  #inputs = tf.keras.layers.Input(shape=[256, 256, 3])\n",
    "  \n",
    "    inputs = tf.keras.layers.Input(shape=[256, 256, 1])\n",
    "    down_stack = [\n",
    "        downsample(64, 4, apply_batchnorm=False),  # (batch_size, 128, 128, 64)\n",
    "        downsample(128, 4),  # (batch_size, 64, 64, 128)\n",
    "        downsample(256, 4),  # (batch_size, 32, 32, 256)\n",
    "        downsample(512, 4),  # (batch_size, 16, 16, 512)\n",
    "        downsample(512, 4),  # (batch_size, 8, 8, 512)\n",
    "        downsample(512, 4),  # (batch_size, 4, 4, 512)\n",
    "        downsample(512, 4),  # (batch_size, 2, 2, 512)\n",
    "        downsample(512, 4),  # (batch_size, 1, 1, 512)\n",
    "        ]\n",
    "\n",
    "    up_stack = [\n",
    "        upsample(512, 4, apply_dropout=True),  # (batch_size, 2, 2, 1024)\n",
    "        upsample(512, 4, apply_dropout=True),  # (batch_size, 4, 4, 1024)\n",
    "        upsample(512, 4, apply_dropout=True),  # (batch_size, 8, 8, 1024)\n",
    "        upsample(512, 4),  # (batch_size, 16, 16, 1024)\n",
    "        upsample(256, 4),  # (batch_size, 32, 32, 512)\n",
    "        upsample(128, 4),  # (batch_size, 64, 64, 256)\n",
    "        upsample(64, 4),  # (batch_size, 128, 128, 128)\n",
    "        ]\n",
    "\n",
    "    OUTPUT_CHANNELS = 1\n",
    "\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n",
    "                                         strides=2,\n",
    "                                         padding='same',\n",
    "                                         kernel_initializer=initializer,\n",
    "                                         activation='tanh')  # (batch_size, 256, 256, 3)\n",
    "\n",
    "    x = inputs\n",
    "\n",
    "    # Downsampling through the model\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = tf.keras.layers.Concatenate()([x, skip])\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b22c1b-5d1a-4147-9701-8f3b9d03e54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a dimension on the end to account for channels\n",
    "inp = tf.expand_dims(inp, -1) # expand dimensions as \"channels last\"\n",
    "#add a dimension on the front to account for batch_size\n",
    "print (f\"inp.shape = {inp.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c282648-5544-4ad9-a9c0-647973014f70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen_output = generator(inp[tf.newaxis, ...], training=False)\n",
    "plt.imshow(gen_output[0, ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6e9fcb-c433-4f7f-a3d3-73012147c43a",
   "metadata": {},
   "source": [
    "## Define the generator loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e991a93-0235-4b18-aa1c-5cc3a4ef1cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GANs learn a loss that adapts to the data, while cGANs learn a structured loss that penalizes\n",
    "# a possible structure that differs from the network output and the target image, as described \n",
    "# in the pix2pix paper.\n",
    "#The generator loss is a sigmoid cross-entropy loss of the generated images and an array of\n",
    "# ones.\n",
    "#The pix2pix paper also mentions the L1 loss, which is a MAE (mean absolute error) between the\n",
    "# generated image and the target image.\n",
    "#This allows the generated image to become structurally similar to the target image.\n",
    "#The formula to calculate the total generator loss is gan_loss + LAMBDA * l1_loss, where\n",
    "# LAMBDA = 100. This value was decided by the authors of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c43d44d-f19c-4f37-b44c-e3da8a5fb90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 100\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "  # Mean absolute error\n",
    "  l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "\n",
    "  total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
    "\n",
    "  return total_gen_loss, gan_loss, l1_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba59364-d26d-47cb-b3e5-3391608acc2f",
   "metadata": {},
   "source": [
    "## Build the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38ab81f-8d1d-4837-8b3c-786afb4ea526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The discriminator in the pix2pix cGAN is a convolutional PatchGAN classifierâ€”it tries to\n",
    "# classify if each image patch is real or not real, as described in the pix2pix paper.\n",
    "#\n",
    "#Each block in the discriminator is: Convolution -> Batch normalization -> Leaky ReLU.\n",
    "#The shape of the output after the last layer is (batch_size, 30, 30, 1).\n",
    "#Each 30 x 30 image patch of the output classifies a 70 x 70 portion of the input image.\n",
    "#The discriminator receives 2 inputs:\n",
    "#       (1) The input image and the target image, which it should classify as real.\n",
    "#       (2) The input image and the generated image (the output of the generator), which it should\n",
    "#              classify as fake.\n",
    "#Use tf.concat([inp, tar], axis=-1) to concatenate these 2 inputs together.\n",
    "#Let's define the discriminator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630cd857-55d8-40ce-b9a3-d78fb3ab30ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator():\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  #inp = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image') - B&W image, hence reduced to 1 channel\n",
    "  #tar = tf.keras.layers.Input(shape=[256, 256, 3], name='target_image')\n",
    "  inp = tf.keras.layers.Input(shape=[256, 256, 1], name='input_image')\n",
    "  tar = tf.keras.layers.Input(shape=[256, 256, 1], name='target_image')    \n",
    "\n",
    "  x = tf.keras.layers.concatenate([inp, tar])  # (batch_size, 256, 256, channels*2)\n",
    "\n",
    "  down1 = downsample(64, 4, False)(x)  # (batch_size, 128, 128, 64)\n",
    "  down2 = downsample(128, 4)(down1)  # (batch_size, 64, 64, 128)\n",
    "  down3 = downsample(256, 4)(down2)  # (batch_size, 32, 32, 256)\n",
    "\n",
    "  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (batch_size, 34, 34, 256)\n",
    "  conv = tf.keras.layers.Conv2D(512, 4, strides=1,\n",
    "                                kernel_initializer=initializer,\n",
    "                                use_bias=False)(zero_pad1)  # (batch_size, 31, 31, 512)\n",
    "\n",
    "  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n",
    "\n",
    "  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n",
    "\n",
    "  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (batch_size, 33, 33, 512)\n",
    "\n",
    "  last = tf.keras.layers.Conv2D(1, 4, strides=1,\n",
    "                                kernel_initializer=initializer)(zero_pad2)  # (batch_size, 30, 30, 1)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inp, tar], outputs=last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799193ed-f44f-44e4-95bb-ab9f748ed74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_out = discriminator([inp[tf.newaxis, ...], gen_output], training=False)\n",
    "#plt.imshow(disc_out[0, ..., -1], vmin=-20, vmax=20, cmap='RdBu_r')\n",
    "#plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcebf23-9d45-4cf4-82a5-4787d3a35b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2602d7a-275a-48d2-ae94-79728fd8205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator()\n",
    "tf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806a077b-b94d-4cee-b8c7-54a576d225c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()\n",
    "tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4cf40e",
   "metadata": {
    "id": "6a4cf40e"
   },
   "source": [
    "### model - simple autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d15162",
   "metadata": {
    "id": "c7d15162"
   },
   "source": [
    "let us start with the simplest possible model - restoring 1 column of MEL spectrogram (256 entries)\n",
    "this loses out on the previous time snapshots, but should be simple to train\n",
    "Accordingly, instead of Conv2d, we will have Conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459b8178",
   "metadata": {
    "executionInfo": {
     "elapsed": 4686,
     "status": "ok",
     "timestamp": 1707244178364,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "459b8178"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "#from tensorflow.keras.layers import Conv2D, Conv1D, MaxPooling2D, Flatten, Dense\n",
    "#from tensorflow.keras.layers import MaxPooling1D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e180ab8a",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1707244178375,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "e180ab8a"
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_encoder():\n",
    "    '''returns an encoder model, of output_shape equals to latent_dimension'''\n",
    "    encoder = models.Sequential()\n",
    "    encoder.add(layers.Dense(100, input_dim=256, activation='tanh'))\n",
    "\n",
    "    return encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762e08fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1707244182012,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "762e08fc",
    "outputId": "8c3528db-9454-4098-ea5e-542e4b5fce74"
   },
   "outputs": [],
   "source": [
    "encoder = build_encoder()\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c8a899",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1707244181037,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "97c8a899"
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_decoder():\n",
    "    decoder = models.Sequential()\n",
    "\n",
    "    decoder.add(layers.Dense(256, input_dim=100, activation='relu'))\n",
    "\n",
    "    return decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3f6ab8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1707244184828,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "2e3f6ab8",
    "outputId": "8bd2255d-1472-4d1c-a60b-7b924b871cd2"
   },
   "outputs": [],
   "source": [
    "decoder = build_decoder()\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aab9e3",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1707244188261,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "62aab9e3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "autoencoder = models.Sequential([encoder, decoder])\n",
    "#autoencoder.compile(loss=\"mse\", optimizer=Adam(learning_rate=0.1))\n",
    "optimizer = Adam()\n",
    "\n",
    "autoencoder.compile(loss='mse',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d738b0cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1052,
     "status": "ok",
     "timestamp": 1707244192494,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "d738b0cb",
    "outputId": "ab60a6aa-d9bc-430c-f38e-1d9cadc034cb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332d7269",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1707244192494,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "332d7269"
   },
   "outputs": [],
   "source": [
    "train_sg_t =  np.transpose(train_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb158a5a",
   "metadata": {
    "executionInfo": {
     "elapsed": 415,
     "status": "ok",
     "timestamp": 1707244200158,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "bb158a5a"
   },
   "outputs": [],
   "source": [
    "degraded_train_sg_t =  np.transpose(degraded_train_sg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d80b5b0",
   "metadata": {
    "id": "8d80b5b0"
   },
   "source": [
    "### train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4e2f28",
   "metadata": {
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1707249871644,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "bb4e2f28"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def reinitialize(model):\n",
    "    for l in model.layers:\n",
    "        if isinstance(l, tf.keras.Model):\n",
    "            reinitialize(l)\n",
    "            continue\n",
    "        if hasattr(l,\"kernel_initializer\"):\n",
    "            l.kernel.assign(l.kernel_initializer(tf.shape(l.kernel)))\n",
    "        if hasattr(l,\"bias_initializer\"):\n",
    "            l.bias.assign(l.bias_initializer(tf.shape(l.bias)))\n",
    "        if hasattr(l,\"recurrent_initializer\"):\n",
    "            l.recurrent_kernel.assign(l.recurrent_initializer(tf.shape(l.recurrent_kernel)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be4ec0a",
   "metadata": {
    "id": "3be4ec0a"
   },
   "outputs": [],
   "source": [
    "reinitialize(autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57165de2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 128574,
     "status": "ok",
     "timestamp": 1707244462571,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "57165de2",
    "outputId": "af4d30c2-e86c-4232-8e83-f0c61894501d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "history = autoencoder.fit(train_sg_t, train_sg_t ,\n",
    "                           validation_split = 0.2,\n",
    "                           epochs=100,\n",
    "                           batch_size=32,\n",
    "                           workers=3,\n",
    "                           use_multiprocessing=True,\n",
    "                           verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b08db",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 1112,
     "status": "ok",
     "timestamp": 1707244468841,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "0d5b08db",
    "outputId": "68d58ca0-7e25-46d7-c780-354aab1e1893"
   },
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history)\n",
    "\n",
    "headers = list(hist_df.columns.values)\n",
    "\n",
    "\n",
    "plot = hist_df[[headers[0], headers[2]]].plot(title=f\"{headers[0]}, {headers[2]}\", logy=True)\n",
    "#plot = hist_df[[headers[1], headers[3]]].plot(title=f\"{headers[1]}, {headers[3]}\", logy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d417d2",
   "metadata": {
    "id": "62d417d2"
   },
   "source": [
    "### save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ef431a",
   "metadata": {
    "id": "a9ef431a"
   },
   "outputs": [],
   "source": [
    "models.save_model(autoencoder, 'autoencoder_001a')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50964a7",
   "metadata": {
    "id": "a50964a7"
   },
   "source": [
    "### how does the model sound?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b324b210",
   "metadata": {
    "executionInfo": {
     "elapsed": 550,
     "status": "ok",
     "timestamp": 1707244551775,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "b324b210"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae714e9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1718,
     "status": "ok",
     "timestamp": 1707244554229,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "ae714e9f",
    "outputId": "5ce8682e-064d-40a4-b75e-c02155a00482"
   },
   "outputs": [],
   "source": [
    "restored_test_sg_t = autoencoder.predict(np.transpose(degraded_test_sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9fabff",
   "metadata": {
    "executionInfo": {
     "elapsed": 27631,
     "status": "ok",
     "timestamp": 1707244581858,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "7c9fabff"
   },
   "outputs": [],
   "source": [
    "reconstructed_restored_test = pp.spectrogram_2_waveform (np.transpose(restored_test_sg_t), sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa62d9e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "executionInfo": {
     "elapsed": 34147,
     "status": "ok",
     "timestamp": 1707244616003,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "4fa62d9e",
    "outputId": "c1c9e66a-31f3-4861-f4b6-b199e4d30e3e"
   },
   "outputs": [],
   "source": [
    "print (\"reconstructed_test\")\n",
    "IPython.display.display(IPython.display.Audio(data=reconstructed_test,  rate=sr))\n",
    "pp.plot_mel_spectrogram(test_sg,sr, figsize=(2,2))\n",
    "\n",
    "\n",
    "print (\"reconstructed_restored_degraded_test\")\n",
    "IPython.display.display(IPython.display.Audio(data=reconstructed_restored_test,  rate=sr))\n",
    "pp.plot_mel_spectrogram(np.transpose(restored_test_sg_t),sr, figsize=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SHVJpHrBt19r",
   "metadata": {
    "id": "SHVJpHrBt19r"
   },
   "source": [
    "# even simpler (10, 256) model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pcn5NlVMthFY",
   "metadata": {
    "executionInfo": {
     "elapsed": 404,
     "status": "ok",
     "timestamp": 1707245064463,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "pcn5NlVMthFY"
   },
   "outputs": [],
   "source": [
    "### simper model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_the_simplest_model_possible():\n",
    "    simplest_model = models.Sequential()\n",
    "    simplest_model.add(layers.Dense(10, input_dim=256, activation='relu'))\n",
    "    simplest_model.add(layers.Dense(256, input_dim=100, activation='relu'))\n",
    "    return simplest_model\n",
    "simplest_model = build_the_simplest_model_possible()\n",
    "optimizer = Adam()\n",
    "\n",
    "simplest_model.compile(loss='mse',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594_USRpxcKd",
   "metadata": {
    "executionInfo": {
     "elapsed": 1051,
     "status": "ok",
     "timestamp": 1707249400338,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "594_USRpxcKd"
   },
   "outputs": [],
   "source": [
    "# Cache to RAM to speed up the training. This requires arrays to be converted to Datasets\n",
    "from tensorflow import data\n",
    "#from tensorflow.data.Dataset import cache\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = data.Dataset.from_tensor_slices((np.transpose(train_sg), np.transpose(train_sg))).batch(10000)\n",
    "validation_dataset = data.Dataset.from_tensor_slices((np.transpose(test_sg), np.transpose(test_sg))).batch(3000)\n",
    "\n",
    "\n",
    "AUTOTUNE = data.experimental.AUTOTUNE\n",
    "train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "#val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KJZ62DtG_6l0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1707249536078,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "KJZ62DtG_6l0",
    "outputId": "83fa3eba-9099-4491-a0e6-447854c7d044"
   },
   "outputs": [],
   "source": [
    "print (f\"train_sg.shape={train_sg.shape}\")\n",
    "print (f\"test_sg.shape={test_sg.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VrSIh42XTlL4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 103695,
     "status": "ok",
     "timestamp": 1707256047741,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "VrSIh42XTlL4",
    "outputId": "1f09f197-8e02-421b-f1d0-babd5ef5ed51"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import BackupAndRestore\n",
    "\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "br = BackupAndRestore(\n",
    "    backup_dir=\"training_backup\",\n",
    "    save_freq=\"epoch\",\n",
    "    delete_checkpoint=True\n",
    ")\n",
    "reinitialize(simplest_model)\n",
    "history = simplest_model.fit( x=train_dataset,\n",
    "                           batch_size=4,\n",
    "                           validation_data=validation_dataset,\n",
    "                           epochs=500,\n",
    "                           verbose=1,\n",
    "                           workers=24,\n",
    "                           callbacks=[es,br],\n",
    "                           use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "V1QECPXtU784",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 1351,
     "status": "ok",
     "timestamp": 1707256057110,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "V1QECPXtU784",
    "outputId": "72637f20-c5f4-4492-8327-acf5cc336094"
   },
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history)\n",
    "headers = list(hist_df.columns.values)\n",
    "plot = hist_df[[headers[0], headers[2]]].plot(title=f\"{headers[0]}, {headers[2]}\", logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7S4CxHlYVUO-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "executionInfo": {
     "elapsed": 34710,
     "status": "ok",
     "timestamp": 1707256104689,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "7S4CxHlYVUO-",
    "outputId": "0ac9f234-bbae-4a65-e62a-5c5c91144756",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models.save_model(simplest_model, 'autoencoder_baseline_10-256-trained-on-good')\n",
    "\n",
    "restored_test_sg_t = simplest_model.predict(np.transpose(degraded_test_sg))\n",
    "\n",
    "print (\"reconstructed_test\")\n",
    "IPython.display.display(IPython.display.Audio(data=reconstructed_test,  rate=sr))\n",
    "pp.plot_mel_spectrogram(test_sg,sr, figsize=(2,2))\n",
    "\n",
    "\n",
    "print (\"reconstructed_restored_degraded_test\")\n",
    "IPython.display.display(IPython.display.Audio(data=pp.spectrogram_2_waveform(np.transpose(restored_test_sg_t), sr=sr),  rate=sr))\n",
    "pp.plot_mel_spectrogram(np.transpose(restored_test_sg_t),sr, figsize=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1145b3a4-49f6-41c6-9021-bdce94735645",
   "metadata": {},
   "source": [
    "## preprocessing  - add log on the input to the model to reduce the variance of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cb3785-f852-486c-9932-487ddfb33428",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.DataFrame(np.transpose(train_sg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c8625d-a0df-48cc-b4ac-7224aa8ec23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a61646-b35a-445d-b2c7-e7ab402043c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inp = np.log(inp_long[:, 0:255]) # inp_long[:, 0:255]\n",
    "#note - adding 0.00000001 to all entries to prevent log(0)\n",
    "log_train_dataset = data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        np.log(\n",
    "            0.00000001 + np.transpose(\n",
    "                train_sg\n",
    "            )\n",
    "        ), \n",
    "        np.log(\n",
    "            0.00000001 + np.transpose(\n",
    "                train_sg\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ").batch(10000)\n",
    "log_validation_dataset = data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        np.log(\n",
    "            0.00000001 + np.transpose(\n",
    "                test_sg\n",
    "            )\n",
    "        ), \n",
    "        np.log(\n",
    "            0.00000001 + np.transpose(\n",
    "                test_sg\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ").batch(3000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcb5648-36e9-4cee-a9b9-552c0c8e3378",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = data.experimental.AUTOTUNE\n",
    "log_train_dataset = log_train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "log_validation_dataset = log_validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb248cfb-8b0e-4e5a-9169-46cc3e0d06d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "simplest_model_on_log = build_the_simplest_model_possible()\n",
    "optimizer = Adam()\n",
    "\n",
    "simplest_model_on_log.compile(loss='mse',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1653ec90-df91-4f57-ab4a-7885c1f8ba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import BackupAndRestore\n",
    "\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "br = BackupAndRestore(\n",
    "    backup_dir=\"training_backup\",\n",
    "    save_freq=\"epoch\",\n",
    "    delete_checkpoint=True\n",
    ")\n",
    "reinitialize(simplest_model_on_log)\n",
    "history = simplest_model_on_log.fit( x=log_train_dataset,\n",
    "                           batch_size=4,\n",
    "                           validation_data=log_validation_dataset,\n",
    "                           epochs=500,\n",
    "                           verbose=1,\n",
    "                           workers=24,\n",
    "                           callbacks=[es,br],\n",
    "                           use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf07e578-f5c3-4b18-be7b-976d4c6baaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history)\n",
    "headers = list(hist_df.columns.values)\n",
    "plot = hist_df[[headers[0], headers[2]]].plot(title=f\"{headers[0]}, {headers[2]}\", logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d2aef6-6432-4f47-b83c-607437a96af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#models.save_model(simplest_model, 'autoencoder_baseline_10-256-trained-on-good')\n",
    "\n",
    "log_restored_test_sg_t = simplest_model_on_log.predict(np.log(0.00000001 + np.transpose(degraded_test_sg)))\n",
    "\n",
    "restored_test_sg_t = (np.exp(log_restored_test_sg_t)) - 0.00000001 \n",
    "\n",
    "print (\"reconstructed_test\")\n",
    "IPython.display.display(IPython.display.Audio(data=reconstructed_test,  rate=sr))\n",
    "pp.plot_mel_spectrogram(test_sg,sr, figsize=(2,2))\n",
    "\n",
    "\n",
    "print (\"reconstructed_restored_degraded_test\")\n",
    "IPython.display.display(IPython.display.Audio(data=pp.spectrogram_2_waveform(np.transpose(restored_test_sg_t), sr=sr),  rate=sr))\n",
    "pp.plot_mel_spectrogram(np.transpose(restored_test_sg_t),sr, figsize=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qOHf1uBRV2Q3",
   "metadata": {
    "id": "qOHf1uBRV2Q3"
   },
   "source": [
    "# how about training the simpler model on degraded rather than perfect audio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t378XfSUW2Zo",
   "metadata": {
    "executionInfo": {
     "elapsed": 408,
     "status": "ok",
     "timestamp": 1707255532577,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "t378XfSUW2Zo"
   },
   "outputs": [],
   "source": [
    "# Cache to RAM to speed up the training. This requires arrays to be converted to Datasets\n",
    "from tensorflow import data\n",
    "#from tensorflow.data.Dataset import cache\n",
    "\n",
    "train_dataset = data.Dataset.from_tensor_slices((np.transpose(degraded_train_sg), np.transpose(train_sg))).batch(10000)\n",
    "validation_dataset = data.Dataset.from_tensor_slices((np.transpose(degraded_test_sg), np.transpose(test_sg))).batch(3000)\n",
    "\n",
    "\n",
    "AUTOTUNE = data.experimental.AUTOTUNE\n",
    "train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "#val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PePLUVbJXFGx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39090,
     "status": "ok",
     "timestamp": 1707255603471,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "PePLUVbJXFGx",
    "outputId": "5ecbb7eb-adea-4b72-e06c-b447a7d16adb"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "br = BackupAndRestore(\n",
    "    backup_dir=\"training_backup\",\n",
    "    save_freq=\"epoch\",\n",
    "    delete_checkpoint=True\n",
    ")\n",
    "\n",
    "history = simplest_model.fit( x=train_dataset,\n",
    "                           batch_size=4,\n",
    "                           validation_data=validation_dataset,\n",
    "                           epochs=1000,\n",
    "                           verbose=1,\n",
    "                           workers=24,\n",
    "                           callbacks=[es,br],\n",
    "                           use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "An8tjbLMXMH5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1707255632901,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "An8tjbLMXMH5",
    "outputId": "775087fc-8080-4ed7-f1b6-e0d3a09e83e6"
   },
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history)\n",
    "headers = list(hist_df.columns.values)\n",
    "plot = hist_df[[headers[0], headers[2]]].plot(title=f\"{headers[0]}, {headers[2]}\", logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6u5nefQNXPSV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "executionInfo": {
     "elapsed": 34537,
     "status": "ok",
     "timestamp": 1707255781380,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "6u5nefQNXPSV",
    "outputId": "0c3c9ffe-778b-434e-cf71-9ea02d67c5e9"
   },
   "outputs": [],
   "source": [
    "models.save_model(simplest_model, 'autoencoder_baseline_10-256-trained-on_degraded')\n",
    "\n",
    "restored_test_sg_t = simplest_model.predict(np.transpose(degraded_test_sg))\n",
    "\n",
    "print (\"reconstructed_test\")\n",
    "IPython.display.display(IPython.display.Audio(data=reconstructed_test,  rate=sr))\n",
    "pp.plot_mel_spectrogram(test_sg,sr, figsize=(2,2))\n",
    "\n",
    "\n",
    "print (\"reconstructed_restored_degraded_test\")\n",
    "IPython.display.display(IPython.display.Audio(data=reconstructed_restored_test,  rate=sr))\n",
    "pp.plot_mel_spectrogram(np.transpose(restored_test_sg_t),sr, figsize=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hGoWlrKuZJ61",
   "metadata": {
    "id": "hGoWlrKuZJ61"
   },
   "source": [
    "# try convolutional autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XeN7QWtgZUIm",
   "metadata": {
    "executionInfo": {
     "elapsed": 606,
     "status": "ok",
     "timestamp": 1707257043112,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "XeN7QWtgZUIm"
   },
   "outputs": [],
   "source": [
    "def build_convolutional_autoencoder():\n",
    "    conv_ac = models.Sequential()\n",
    "    conv_ac.add(layers.Reshape([256,1], input_shape=[256]))\n",
    "    conv_ac.add(layers.Conv1D(16, kernel_size=6, padding=\"same\", input_dim=[256,1], activation='selu'))\n",
    "    conv_ac.add(layers.MaxPool1D(pool_size=4))\n",
    "    conv_ac.add(layers.Conv1D(32, kernel_size=6, padding=\"same\", activation='selu'))\n",
    "    conv_ac.add(layers.MaxPool1D(pool_size=4))\n",
    "    conv_ac.add(layers.Conv1D(64, kernel_size=6, padding=\"same\", activation='selu'))\n",
    "    conv_ac.add(layers.MaxPool1D(pool_size=4))\n",
    "\n",
    "    conv_ac.add(layers.Conv1DTranspose(32, kernel_size=6, strides=4, padding=\"same\", activation='selu'))\n",
    "    conv_ac.add(layers.Conv1DTranspose(16, kernel_size=6, strides=4, padding=\"same\", activation='selu'))\n",
    "    conv_ac.add(layers.Conv1DTranspose(1, kernel_size=6, strides=4, padding=\"same\", activation='relu'))\n",
    "\n",
    "\n",
    "    return conv_ac\n",
    "conv_ac = build_convolutional_autoencoder()\n",
    "optimizer = Adam()\n",
    "\n",
    "conv_ac.compile(loss='mse',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tGbeJJhGd4mC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1707257351051,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "tGbeJJhGd4mC",
    "outputId": "9695b240-7857-4bed-caba-135b02fc06aa"
   },
   "outputs": [],
   "source": [
    "conv_ac.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dQO7f0OQc-Zw",
   "metadata": {
    "executionInfo": {
     "elapsed": 1049,
     "status": "ok",
     "timestamp": 1707257145300,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "dQO7f0OQc-Zw"
   },
   "outputs": [],
   "source": [
    "# Cache to RAM to speed up the training. This requires arrays to be converted to Datasets\n",
    "from tensorflow import data\n",
    "#from tensorflow.data.Dataset import cache\n",
    "\n",
    "train_dataset = data.Dataset.from_tensor_slices((np.transpose(degraded_train_sg), np.transpose(train_sg))).batch(10000)\n",
    "validation_dataset = data.Dataset.from_tensor_slices((np.transpose(degraded_test_sg), np.transpose(test_sg))).batch(3000)\n",
    "\n",
    "\n",
    "AUTOTUNE = data.experimental.AUTOTUNE\n",
    "train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "#val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VCVLs408dLHh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23272,
     "status": "ok",
     "timestamp": 1707257260026,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "VCVLs408dLHh",
    "outputId": "e55b4cb7-ba44-43f2-f373-f43f5adbd119"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "br = BackupAndRestore(\n",
    "    backup_dir=\"training_backup\",\n",
    "    save_freq=\"epoch\",\n",
    "    delete_checkpoint=True\n",
    ")\n",
    "\n",
    "history = conv_ac.fit( x=train_dataset,\n",
    "                           batch_size=4,\n",
    "                           validation_data=validation_dataset,\n",
    "                           epochs=100,\n",
    "                           verbose=1,\n",
    "                           workers=24,\n",
    "                           callbacks=[es,br],\n",
    "                           use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O_sbcVJidn0T",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 946,
     "status": "ok",
     "timestamp": 1707257285310,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "O_sbcVJidn0T",
    "outputId": "4e06332b-8591-4473-d519-c4e797daa4cd"
   },
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history)\n",
    "headers = list(hist_df.columns.values)\n",
    "plot = hist_df[[headers[0], headers[2]]].plot(title=f\"{headers[0]}, {headers[2]}\", logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7IW6I9bve9_R",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1707257626707,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "7IW6I9bve9_R",
    "outputId": "a2901576-08ae-46fb-9bbc-c673fc26139e"
   },
   "outputs": [],
   "source": [
    "restored_test_sg_t = conv_ac.predict(np.transpose(degraded_test_sg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t_YTAcbuf_MP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1707257907449,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "t_YTAcbuf_MP",
    "outputId": "28fd710e-f582-4e91-c9c6-509e11bb794d"
   },
   "outputs": [],
   "source": [
    "restored_test_sg_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hv2nbgfqgEf9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 919,
     "status": "ok",
     "timestamp": 1707257920960,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "Hv2nbgfqgEf9",
    "outputId": "3575a1f3-fb9e-462e-b92d-efe5f2627c38"
   },
   "outputs": [],
   "source": [
    "reconstructed_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EhLsVRVWdxwb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "executionInfo": {
     "elapsed": 23873,
     "status": "ok",
     "timestamp": 1707257861622,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "EhLsVRVWdxwb",
    "outputId": "bdca4df1-c8e7-4e83-904f-0d0f1afed74e"
   },
   "outputs": [],
   "source": [
    "models.save_model(conv_ac, 'conv_16-32-64-32-16-1')\n",
    "\n",
    "restored_test_sg_t = conv_ac.predict(np.transpose(degraded_test_sg))[:, :, 0]\n",
    "\n",
    "print (\"reconstructed_test\")\n",
    "IPython.display.display(IPython.display.Audio(data=reconstructed_test,  rate=sr))\n",
    "pp.plot_mel_spectrogram(test_sg,sr, figsize=(2,2))\n",
    "\n",
    "\n",
    "print (\"reconstructed_restored_degraded_test\")\n",
    "IPython.display.display(IPython.display.Audio(data=np.transpose(restored_test_sg_t),  rate=sr))\n",
    "pp.plot_mel_spectrogram(np.transpose(restored_test_sg_t),sr, figsize=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BCb-rK4QTl1Z",
   "metadata": {
    "id": "BCb-rK4QTl1Z"
   },
   "source": [
    "# Simple autoencoder (100, 256 dense) model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "G8fxwY_wBfVs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 474,
     "status": "ok",
     "timestamp": 1707250046402,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "G8fxwY_wBfVs",
    "outputId": "19e490c6-0ce7-4aea-fcb0-8cfc1efe6e7b"
   },
   "outputs": [],
   "source": [
    "reinitialize(autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EgrQPJ07vFQj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 925982,
     "status": "ok",
     "timestamp": 1707250975682,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "EgrQPJ07vFQj",
    "outputId": "d108d846-ee1b-4d65-db5f-2bc9d7a5cc18"
   },
   "outputs": [],
   "source": [
    "history = autoencoder.fit( x=train_dataset,\n",
    "                           batch_size=4,\n",
    "                           validation_data=validation_dataset,\n",
    "                           epochs=10000,\n",
    "                           verbose=1,\n",
    "                           workers=24,\n",
    "                           use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iir7fkMH_E0U",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "executionInfo": {
     "elapsed": 1568,
     "status": "ok",
     "timestamp": 1707250984739,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "iir7fkMH_E0U",
    "outputId": "7458a418-5d65-4a3a-88bb-20b02f4aeff1"
   },
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(history.history)\n",
    "headers = list(hist_df.columns.values)\n",
    "plot = hist_df[[headers[0], headers[2]]].plot(title=f\"{headers[0]}, {headers[2]}\", logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v6sKMIbQF2aW",
   "metadata": {
    "executionInfo": {
     "elapsed": 1591,
     "status": "ok",
     "timestamp": 1707251214585,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "v6sKMIbQF2aW"
   },
   "outputs": [],
   "source": [
    "models.save_model(autoencoder, 'autoencoder_baseline_10000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3jF-cBaVGiQR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1728,
     "status": "ok",
     "timestamp": 1707251293597,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "3jF-cBaVGiQR",
    "outputId": "a96ce6f6-2e3b-4353-a5df-9292fc10233d"
   },
   "outputs": [],
   "source": [
    "restored_test_sg_t = autoencoder.predict(np.transpose(degraded_test_sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iXksa59zFxyj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "executionInfo": {
     "elapsed": 33268,
     "status": "ok",
     "timestamp": 1707251331146,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "iXksa59zFxyj",
    "outputId": "adf01fdf-1e98-4d67-9868-e6c42df70fd1"
   },
   "outputs": [],
   "source": [
    "print (\"reconstructed_test\")\n",
    "IPython.display.display(IPython.display.Audio(data=reconstructed_test,  rate=sr))\n",
    "pp.plot_mel_spectrogram(test_sg,sr, figsize=(2,2))\n",
    "\n",
    "\n",
    "print (\"reconstructed_restored_degraded_test\")\n",
    "IPython.display.display(IPython.display.Audio(data=reconstructed_restored_test,  rate=sr))\n",
    "pp.plot_mel_spectrogram(np.transpose(restored_test_sg_t),sr, figsize=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rECHHhiNHe6j",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1707254385440,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": 0
    },
    "id": "rECHHhiNHe6j"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import BackupAndRestore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NOy8B4rmTbt8",
   "metadata": {
    "id": "NOy8B4rmTbt8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c241373",
   "metadata": {
    "id": "2c241373"
   },
   "source": [
    "## same  model with reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7683ef0a",
   "metadata": {
    "id": "7683ef0a"
   },
   "source": [
    "## same  model with dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7391d16a",
   "metadata": {
    "id": "7391d16a"
   },
   "source": [
    "## same  model with dropout & reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474a897a",
   "metadata": {
    "id": "474a897a"
   },
   "outputs": [],
   "source": [
    "models.save_model(autoencoder_do_reg, 'autoencoder_002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15396a80",
   "metadata": {
    "id": "15396a80"
   },
   "outputs": [],
   "source": [
    "models.save_model(autoencoder_do_reg_selu, 'autoencoder_003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b03663",
   "metadata": {
    "id": "52b03663"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "https://github.com/RomanZhvanskiy/microphone_enhancer_gh/blob/better_models_and_gridsearch/.ipynb_checkpoints/Speech_enhancement_6-checkpoint.ipynb",
     "timestamp": 1707309327642
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
